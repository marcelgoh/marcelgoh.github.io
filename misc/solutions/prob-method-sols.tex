\input fontmac
\input mathmac

\def\given{\,|\,}
\def\biggiven{\,\big|\,}
\def\A{{\cal A}}
\def\B{{\cal B}}
\def\C{{\cal C}}
\def\F{{\cal F}}
\def\G{{\cal G}}

\maketitle{The Probabilistic Method}{exercise solutions by}{Marcel K. Goh}{9 March 2022}

\floattext5 \ninebf Note. \ninepoint
A star indicates a starred problem in the text; these are supposed to be harder.
I have decided to put my work here even when I haven't solved the problem yet, so that when I come back
later I can see what I've tried. I won't put the black square
\hbox{\kern1.5pt\vrule width2.5pt height6pt depth1.5pt\kern1.5pt}
until I think the proof
is actually done. Also I wrote $\log$ everywhere to mean $\log_e$
even though the text uses $\ln$.

\bigskip

\section 1. The Basic Method

\proclaim Exercise 1.1. Prove that if there is a real $p$, with $0\le p\le 1$ such that
$${n\choose k}p^{k\choose 2} + {n\choose t}(1-p)^{t\choose 2} < 1,$$
then the Ramsey number $r(k,t)$ satisfies $r(k,t)>n$. Using this, show that
$$r(4,t) \ge \Omega\bigl(t^{3/2}/ (\log t)^{3/2}\bigr).$$

\proof We follow the proof of Proposition~1.1.1 in the book. We consider a random graph on
$n$ vertices, where each edge is present with probability $p$. Let $K$ be the event that
there is a clique of size $k$ in the graph, and let $I$ be the event that there is an
independent set of size $t$ in the graph. By the union bound,
$$\pr\{ K \cup I\} \le \pr\{K\} + \pr\{I\} \le \sum_{|S| = k} p^{k\choose 2} + \sum_{|S|=t} (1-p)^{t\choose 2}
= {n\choose k}p^{k\choose 2} + {n\choose t}(1-p)^{t\choose 2} < 1.$$
This means that $\pr\{ \neg K \cap \neg I\} > 0$ and since the sample space is finite,
there exists a graph on $n$ vertices with
no clique of size $k$ and no independent set of size $t$ and therefore $r(k,t) > n$.

Next we show that $r(4,t) > \bigl(t/(e\log t)\bigr)^{3/2}$ for large enough $t$. Note that
$${n\choose 4} p^{k\choose 2} + {n\choose t}(1-p)^{t\choose 2}\le
n^4p^6 + {e^tn^t\over t^t}(1-p)^{t^2/4},$$
by the inequalities
$$ {n^k\over k^k} \le {n\choose k} \le {e^k n^k\over k^k}.$$
Setting $n = t^{3/2} / (e\log t)^{3/2}$, we have
$$\eqalign{
n^4p^6 + {e^tn^t\over t^t}(1-p)^{t^2/4} &=
\biggl({tp\over e\log t}\biggr)^6 + {e^t t^{3t/2} \over t^t e^{3t/2} (\log t)^{3t/2}} (1-p)^{t^2/4} \cr
&=\biggl({tp\over e\log t}\biggr)^6 + {t^{t/2} \over e^{t/2} (\log t)^{3t/2}} (1-p)^{t^2/4} \cr
&\le \biggl({tp\over e\log t}\biggr)^6 + \biggl({t(1-p)^{t/2} \over e(\log t)^3}\biggr)^{t/2} \cr
&\le \biggl({tp\over e\log t}\biggr)^6 + \biggl({t \over e^{pt/2+1}(\log t)^3}\biggr)^{t/2},\cr
}$$
where in the last line we used the inequality $1-p \le e^{-p}$.
Choosing $p = 2\log t/t$, we simply need $t$ large enough such that
$$ \biggl({t\over e^{\log t+1} (\log t)^3}\biggr)^{t/2} = 
\biggl({1\over e(\log t)^3}\biggr)^{t/2} < 1- \biggl({2\over e}\biggr)^6,$$
which can be done since the left-hand side goes to $0$.\slug

\proclaim Exercise 1.2. Suppose $n\ge 4$ and let $H$ be an $n$-uniform hypergraph with at most
$4^{n-1}/3^n$ edges. Prove that there is a colouring of the vertices of $H$ by $4$ colours so that in
every edge all $4$ colours are represented.

\proof Let each vertex of $H$ be independently given one of the four colours uniformly at random. (If
$H$ is infinite, it does not matter what colour we give to vertices that do not appear in any edge,
so it suffices to consider $H$ finite, which makes the sample space finite.)
Given some edge $e$ of $H$ with $n$ vertices, there are $4^n$ total ways that $e$ may be coloured,
and for each of the four colours, $3^n$ total ways that $e$ may be coloured using only the other three colours.
Let $K(e)$ denote the event that $e$ does not contain all four colours. By the inclusion-exclusion principle,
$$\pr\bigl\{K(e)\bigr\} = 4\cdot 3^n - 6\cdot 2^n + 4$$
Since $6\cdot 2^n \ge 96 > 4$, the probability that a given edge {\it does not} contain all four colours
is (much) less than $3^n/4^{n-1}$. By the union bound,
$$\pr\Bigl\{ \bigcup_{e\in E(H)} K(e)\Bigr\} \le \sum_{e\in E(H)} \pr\bigl\{K(e)\bigr\}
< {4^{n-1}\over 3^n} \cdot {3^n\over 4^{n-1}} = 1.$$
Since the sample space is finite this implies that there is some colouring of the vertices of $H$
in which every edge has all four colours.\slug

\proclaim \llap{*}Exercise 1.3. Prove that for two independent, identically distributed real random
variables $X$ and $Y$,
$$\pr\bigl\{|X-Y|\le 2\bigr\} \le 3\pr\bigl\{|X-Y|\le 1\bigr\}.$$

\proof [Not done. Need to use independence somehow. I think by symmetry
it is enough to show that $\pr\{1 < X-Y\le 2\}
\le \pr\bigl\{|X-Y|\le 1\bigr\}$ or $\pr\bigl\{X-Y > 1 \biggiven |X-Y|\le 2\bigr\}\le 1/3$.
In the second expression,
$X$ and $Y$ are no longer independent.]

\proclaim \llap{*}Exercise 1.4. Let $G=(V,E)$ be a graph with $n$ vertices and minimum degree $\delta>10$.
Prove that there is a partition of $V$ into two disjoint subsets $A$ and $B$ so that
$|A|\le O\bigl((n\log n)/\delta\bigr)$, and each vertex of $B$ has at least one neighbour in $A$ and at least
one neighbour in $B$.

\proof We follow the construction of the dominating set from the proof of Theorem~1.2.2, since the
required $A$ here is a dominating set with some extra conditions. Let $p$ be chosen later and let $X$
be a random set of vertices obtained by independently selecting each $v\in V$ with probability $p$.
Then as in the proof from the textbook, we let $Y$ be the set of all $v\in V\setminus X$ that have no
neighbours in $X$. At this point $X\cup Y$ is a dominating set, but we are not yet done constructing
$A$, since there may still be elements in $V\setminus (X\cup Y)$ all of whose neighbours belong to $X\cup Y$.
Let $Z\subseteq V\setminus (X\cup Y)$ denote all of these elements. For any given $v\in V$, we
have $\pr\{v\in X\} = p$ and
$$\pr\{v\in Y\} = (1-p)^{\deg(v) + 1} \le (1-p)^{\delta+1} \le e^{-p(\delta+1)},$$
since for $v\in Y$ we need $v$
itself as well as all $\deg(v)$ of its neighbours to not be in $X$. Lastly,
$$\pr\{v\in Z\} = (1-p)\prod_{w\in N(v)} \bigl(p+(1-p)^{\deg(w)+1}\bigr)
\le (1-p)\bigl(p+(1-p)^{\delta+1}\bigr)^\delta \le (1-p)(p+e^{-p(\delta+1)})^\delta.$$
Now we compute
$$\eqalign{
\ex\bigl\{|A|\bigr\} &= \sum_{v\in V} v\in \{X\cup Y\cup Z\} \cr
&\le n\bigl( p + e^{-p(\delta+1)} + (1-p)(p+e^{-p(\delta+1)})^\delta \bigr).\cr
}$$
Since $p+e^{-p(\delta+1)} < 1$, we can remove the $\delta$ from its exponent for the looser but
simpler bound
$$\eqalign{
\ex\bigl\{|A|\bigr\} &\le np + ne^{-p(\delta+1)} + np - np^2 + ne^{-p(\delta+1)} - npe^{-p(\delta+1)}\cr
&=(2-p)(np+ne^{-p(\delta+1)}).\cr
}$$
Setting $p = \log(\delta+1)/(\delta+1)$ just as in the dominating set proof, we have
$$e^{-p(\delta+1)} = {1\over \delta+1}$$
and
$$\ex\bigl\{|A|\bigr\} \le \biggl(2-{\log(\delta+1)\over \delta+1}\biggr)\biggl( n{\log(\delta+1)\over \delta+1}
+ {n\over \delta+1}\biggr) = 2n{\log(\delta+1)\over\delta+1} + o\biggl({n\log\delta\over\delta}\biggr),$$
which has the required asymptotics. It remains to choose an $A$ with $|A|$ at least this average.\slug

\proclaim \llap{*}Exercise 1.5. Let $G=(V,E)$ be a graph on $n\ge 10$ vertices and suppose that if we add
to $G$ any edge not in $G$, the number of copies of a complete graph on $10$ vertices in it increases.
Show that the number of edges of $G$ is at least $8n-36$.

\proof The figure $8n-36$ in the conclusion obscures the fact that we should use Theorem 1.3.3. In
fact,
$$8n-36 = {n^2-n-n^2+17n-72\over 2} = {n(n-1) - (n-8)(n-9)\over 2} = {n\choose 2}-{n-8\choose 2}.$$
Let $F = V^{(2)}\setminus E = \{A_1, A_2,\ldots, A_h\}$ be the set of non-edges in $G$. Since the addition
of any non-edge causes the number of $K_{10}$ subgraphs to increase, we know that for each $A_i$ there
exists a set $X_i$ of size $8$ and disjoint from $A_i$ such that the subgraph induced on
the vertices $A_i\cup X_i$ would be a $K_{10}$ if $A_i$ happened to be in $E$ (which it isn't).
Set $B_i = V\setminus (A_i\cup S_i)$. Clearly, $A_i\cap B_i = \emptyset$ for all $i$. Also,
since $A_i\cup S_i$ is complete except for one missing edge $A_i$, for any $j\ne i$, we have
$A_j\not\subseteq A_i\cup S_i$. This means that $A_j\cap B_i\neq\emptyset$ for all $j\ne i$. Hence
$\bigl\{(A_i,B_i)\bigr\}_{i=1}^h$ is a $(2,n-10)$-system as defined in the chapter, and by
Theorem~1.3.3, $|F| = h\le {2+n-10\choose 2}$. We conclude that $|E|\ge {n\choose 2}-{n-8\choose 2}$.\slug

\proclaim Exercise 1.8. Let $F$ be a finite collection of binary strings of finite lengths and assume no
member of $F$ is a prefix of another one. Let $N_i$ denote the number of strings of length $i$ in $F$.
Prove that
$$\sum_{i\ge 1} {N_i\over 2_i} \le 1.$$

\proof This inequality looks an awful bit like the LYM inequality, so our proof is informed by the proof
of that statement. Let $m$ be the maximum length of any string in $F$ (such a maximum exists because $F$
is finite). Let $b_1, b_2, \ldots, b_m$ be a sequence of independent random variables with
$\pr\{b_i = 0\} = \pr\{b_i = 1\} = 1/2$ for all $1\le i\le m$. Consider the set of strings
$$C = \{b_1, b_1b_2, \ldots, b_1b_2\cdots b_m\}.$$
This is a random set, so we may study the random quantity $|C\cap F|$. Note that $C$ contains
exactly one bitstring of each length, and every string of length $i$ has an equal chance of being in $C$,
namely $2^{-i}$. So
$$\ex\bigl\{|C\cap F|\bigr\} = \sum_{s\in F} \pr\{s\in C\} = \sum_{s\in F} 2^{-|s|}
= \sum_{i\ge 1} {N_i\over 2^i},$$
where $|s|$ is the length of the string $s$. In the last equality we simply grouped strings of the same
length together. On the other hand, $|C\cap F|$ cannot possibly be greater than $1$, since for any two
members of $C$, one must be a prefix of the other. So $\ex\bigl\{|C\cap F|\bigr\} \le 1$ as well,
and this observation completes the proof.\slug

\goodbreak
\section 2. Linearity of Expectation

\proclaim Exercise 2.1. Suppose $n\ge 2$ and let $H=(V,E)$ be an $n$-uniform hypergraph with $|E| = 4^{n-1}$
edges. Show that there is a colouring of $V$ by $4$ colours so that no edge is monochromatic.

\proof Let $\phi$ be a random function from $V$ to $[4]$, so that all $4^n$ possible colourings are equally
likely. Let $X$ be the number of monochromatic edges in $H$ under this colouring; that is,
$$X = \sum_{e \in E} \indic{e\ \hbox{is monochromatic}}.$$
The probability that a given edge $e = \{v_1,\ldots,v_n\}$ is monochromatic is $1/4^{n-1}$, since
$\phi(v_1)$ can be anything, but then $\phi(v_2)$ through to $\phi(v_n)$ each have a $1/4$ chance
of matching $\phi(v_1)$. So
$$\ex\{X\} = \sum_{e\in E} \pr\{e\ \hbox{is monochromatic}\} = {4^{n-1}\over 4^{n-1}}
= 1.$$
We can produce a colouring with $4^{n-1}$ monochromatic edges by setting $\phi(v) = 1$ for all $v\in V$,
so $\pr\{X > 1 \} > 0$. Thus for $\ex\{X\}$ to equal $1$, we must also have $\pr\{X < 1\} > 0$, and since
$X$ is nonnegative, this means that $\pr\{X = 0\} > 0$ and there exists some colouring with no monochromatic
edges.\slug

\proclaim Exercise 2.7. Let $\F$ be a family of subsets of $[n] = \{1,2,\ldots,n\}$ and suppose there are
no $A,B\in \F$ satisfying $A\subseteq B$. Let $\sigma\in S_n$ be a random permutation of the elements of
$[n]$ and consider the random variable
$$ X = \bigl| \bigl\{ i : \{\sigma(1),\sigma(2),\ldots,\sigma(i)\}\in \F\bigr\}\bigr|.$$
By considering the expectation of $X$, prove that $|\F|\le {n\choose \lfloor n/2\rfloor}$.

\proof This is the proof that I said Exercise~1.8 reminded me of. Let $S_i = \{\sigma(1),\ldots,\sigma(i)\}$
and let
$$ C = \{\emptyset, S_1, S_2,\ldots, S_n\}.$$
If there are $i<j$ such that $S_i$ and $S_j$ are both in $\F$, then
$\F$ violates the condition that there are no
$A,B\in \F$ with $A\subseteq B$. So $X\le 1$.
On the other hand, $C$ contains
exactly one set of size $i$ for each $0\le i\le n$ and the probability that $S_i$ is a given
element of $X^{(i)}$ is the same. So letting $N_i$ be the number of sets of size $i$ in $\F$, we have
$$1\ge \ex\{X\} = \sum_{A\in \F} {n\choose |A|}^{-1} = \sum_{i=0}^n N_i {n\choose i}^{-1}\ge
{|\F|\over {n\choose \lfloor n/2\rfloor}},$$
where the last inequality holds because ${n\choose k}$ is maximised when $k=\lfloor n/2\rfloor$
and because the sum of the $N_i$ is $|\F|$.\slug


\goodbreak
\section 3. Alterations

\proclaim Exercise 3.1. As shown in Section~3.1, the Ramsey number $R(k,k)$ satisfies
$$R(k,k) > n-{n\choose k}2^{1-{k\choose 2}}$$
for every integer $n$. Conclude that
$$R(k,k) \ge \bigl(1-o(1)\bigr) {k\over e} 2^{k/2}.$$

\proof We set $n= (k-1) 2^{k/2} /e$ in the above, to get the bound
$$R(k,k) > {k\over e} 2^{k/2} - {1\over e} 2^{k/2} - {(k-1) 2^{k/2} /e \choose k} 2^{1-{k\choose 2}}.$$
Now we apply the inequality ${n\choose k} \le e^kn^k/k^k$, which yields
$$\eqalign{
R(k,k) &> {k\over e} 2^{k/2} - {1\over e} 2^{k/2} - {e^k(k-1)^k 2^{k^2/2} /e^k \over k^k} 2^{1-k^2/2+k/2}\cr
&= {k\over e} 2^{k/2} - {1\over e} 2^{k/2} - \biggl(1-{1\over k}\biggr)^k 2^{1+k/2}. \cr
}$$
Since $(1-1/k)^k\to 1/e$ as $k\to\infty$,
$$R(k,k) > {k\over e}2^{k/2} \biggl( 1 - {1\over k} - {2e(1-1/k)^k \over k}\biggr)
= {k\over e}2^{k/2} \bigl(1-o(1)\bigr).\noskipslug$$

\proclaim Exercise 3.3. Prove that every $3$-uniform hypergraph with $n$ vertices and $m\ge n/3$ edges
contains an independent set (i.e., a set of vertices containing no edges) of size at least
$${2n^{3/2}\over 3\sqrt 3\sqrt m}.$$

\proof We mirror the proof of Theorem~3.2.1. Let $(X\cap \F)$ be a $3$-uniform hypergraph with
$|X| = n$ and $|\F| = m \ge n/3$. Let $S\subseteq X$ be a random subset obtained by independently
putting each $x\in X$ in $S$ with probability $p$, to be chosen later. Of course, $\ex\bigl\{|X|\bigr\} = np$.
What is the expected number of edges contained in $S$? Well, each edge $\{x,y,z\}\in \F$ has probability
$p^3$ of being contained in $S$, so we expect $mp^3$ edges in the subgraph induced by $S$. If
$Y$ is the set of these edges, we now want to choose $p$ to
minimise the quantity $\ex\bigl\{|X|-|Y|\bigr\} = np-mp^3$. The derivative
is $n-3mp^2$ so we ought to set $p=\sqrt{n/3m}$, obtaining
$$\ex\bigl\{ |X|-|Y|\bigr\} = {n^{3/2}-m\sqrt n\over \sqrt{3m}}.$$
Since $m\ge n/3$, we have
$$\ex\bigl\{ |X|-|Y|\bigr\} \ge {n^{3/2}\over \sqrt{3m}}-{n^{3/2}\over 3\sqrt{3m}}={2n^{3/2}\over 3\sqrt{3m}}.$$
This means there exists some set $S\subseteq X$ with the number of vertices minus the number of edges
at least $2n^{3/2}/\bigl(3\sqrt{3m}\bigr)$. Removing one vertex from each edge, we arrive at an independent
set of vertices $S'$ with cardinality at least this quantity.\slug

\section 4. The Second Moment

\proclaim Exercise 4.1. Let $X$ be a random variable taking integral nonnegative values, let $\ex\{X^2\}$
denote the expectation of its square, and let $\var\{X\}$ denote its variance. Prove that
$$\pr\{ X = 0\} \le {\var\{X\} \over \ex\{X^2\}}.$$

\proof Since $X$ is integer and nonnegative, we have $\pr\{X = 0\} = 1-\pr\{X\ge 1\}$ and since
$\var\{X\} = \ex\{X^2\} - \ex\{X\}^2$, to get our result it suffices to show that
$$\pr\{X\ge 1\} \ge {\ex\{X\}^2 \over \ex\{X^2\}}.$$
We start by noting that
$$\ex\{X\} = \sum_{k=0}^\infty k \pr\{X=k\}
= \pr\{X\ge 1\}\sum_{k=1}^\infty {k\pr\{X=k\}\over \pr\{X\ge 1\}}
= \pr\{X\ge 1\}\ex\{ X \given X\ge 1\}.$$
Since the function $x\mapsto x^2$ is convex, we have, by Jensen's inequality,
$$\ex\{X\}^2 = \pr\{X\ge 1\}^2 \ex\{X\given X\ge 1\}^2 \le \pr\{X\ge 1\}^2 \ex\{X^2 \given X\ge 1\}
= \pr\{X\ge 1\} \ex\{X^2\}.$$
Dividing both sides by $\ex\{X^2\}$ gives us what we want.\slug

\proclaim Exercise 4.4. Let $X$ be a random variable with expectation $\ex\{X\} =0$ and variance
$\var\{X\} = \sigma^2$. Prove that for all $\lambda > 0$,
$$\pr\{X\ge \lambda\} \le {\sigma^2\over \sigma^2 + \lambda^2}.$$

\proof Let $\lambda > 0$. Note that if $X\ge \lambda$, then $X$ is also positive so in particular,
for any $a>0$, $X+a$ and $\lambda + a$ are both positive. This implies that $(X+a)^2\ge (\lambda+a)^2$.
Note that since $\var\{X\} = \ex\{X^2\} - \ex\{X\}^2 = \sigma^2$ and $\ex\{X\}=0$, we have
$\ex\{X^2\} = \sigma^2$, which in turn implies that
$$\ex\bigl\{(X+a)^2\bigr\} = \ex\{X^2\} + 2a\ex\{X\} + \ex\{a^2\} = \sigma^2+a^2.$$
Now we take the infimum over all $a>0$ and apply Markov's inequality to get
$$\pr\{X\ge\lambda\} \le \inf_{a > 0} \pr\bigl\{(X+a)^2 \ge (\lambda+a)^2\bigr\} \le
\inf_{a>0} {\sigma^2 + a^2\over (\lambda + a)^2}.$$
We now optimise over $a>0$. We have
$${d\over da} {\sigma^2 + a^2\over (\lambda + a)^2}
  = {(\lambda+a)^2 2a - (\sigma^2+a^2)2(\lambda+a)\over (\lambda + a)^4},$$
which is zero when $a = \sigma^2/\lambda > 0$. Plugging in this value of $a$ gives
$$\pr\{X\ge \lambda\} \le {\sigma^2 + \sigma^4/\lambda^2\over (\lambda + \sigma^2/\lambda)^2}
= {\sigma^2(\lambda + \sigma^2/\lambda) \over \lambda(\lambda + \sigma^2/\lambda)^2}
= {\sigma^2 \over \sigma^2+\lambda^2},$$
exactly what we need.\slug

\section 6. Correlation Inequalities

\proclaim Exercise 6.1. Let $G$ be a graph and let $P$ denote the probability that a random subgraph
of $G$ obtained by picking each edge of $G$ with probability $1/2$ independently is connected (and spanning).
Let $Q$ denote the probability that in a random two-colouring of $G$, where each edge is chosen,
randomly and independently, to be either red or blue, the red graph and the blue graph are both connected
(and spanning). Is $Q\le P^2$?

\solution The answer is yes. Let $\A$ be the family of subsets $A\subseteq E$ such that $G' = (V,A)$
is connected. Let $\C$ be the family of subsets $C\subseteq E$ such that $G'' = (V, E\setminus C)$ is
connected. Adding any edge to $A\in \A$ keeps the set in $\A$, and removing any edge from $C\in \C$ keeps
the set in $\C$, so $\A$ is monotone increasing and $\C$ is monotone decreasing. Note that if $S$ is a
random subset of edges obtained by taking each edge independently with probability $1/2$, then
$\pr\{S = A\} = \pr\{S = E\setminus A\}$ for any fixed $A\subseteq E$, so we find that
$ P = \pr\{\A\} = \pr\{\C\}$. On the other hand, $Q$ is the probability that both $S$ and $E\setminus S$
induce connected subgraphs; i.e., $Q = \pr\{S\in \A\cap \C\}$. Applying Proposition~6.3.1 now gives
$$Q = \pr\{ \A\cap \C\} \le \pr\{\A\} \pr\{\C\} = P^2,$$
as desired.\slug

\proclaim Exercise 6.2. A family of subsets $\G$ is called {\it intersecting} if $G_1\cap G_2\ne \emptyset$
for all $G_1,G_2\in \G$. Let $\F_1, \F_2, \ldots, \F_k$ be $k$ intersecting families of subsets of $X = [n]$.
Prove that
$$\biggl|\bigcup_{i=1}^k \F_i\biggr| \le 2^n - 2^{n-k}.$$

\proof We do this by induction on $k$. If $k=1$, then the upper bound of $2^{n-1}$ on the size of an
intersecting family $\F$ is clear from the fact that $\F$ may contain at most one element of each pair
$(A,X\setminus A)$, and there are $2^{n-1}$ such pairs.
For the induction step, we split
$$\bigcup_{i=1}^k \F_i = \bigcup_{i=1}^{k-1} \F_i \cup \F_k;$$
call the first term on the right-hand side $\A$ and let $\C = 2^X\setminus \F_k$, so that
$$\bigcup_{i=1}^{k-1} \F_i \cup \F_k = \A \cup \F_k = (\A \cap \C) \cup \F_k.$$
Since we are trying to form an upper bound on this quantity,
we might as well assume that $\A$ is maximal; i.e., adding any set to $\F_i$ for $1\le i< k$ causes
$\F_i$ to no longer be intersecting. The claim is that $\A$ is monotone increasing. To see this, suppose
that $A\supseteq B$ and $B\in \A$. This means that $B\in \F_i$ for some $1\le i<k$, and so for any $C\in \F_i$,
$A\cap C \supseteq B\cap C\ne \emptyset$, meaning that $A\in \F_i\subseteq \A$ as well, otherwise we could
add $A$ to $\A$ and contradict maximality. We have actually shown
that the union of any $m$ maximal intersecting families is monotone increasing, so in particular $\F_k$ is
as well. But this means that $\C = 2^X\setminus \F_k$ is monotone decreasing, since if $C\notin \F_k$
and $B\subseteq C$ with $B\in \F_k$, then $\F_k$ would not be monotone increasing. We are now in a position
to apply the cardinality version of Proposition~6.3.1. It gives
$$\biggl|\bigcup_{i=1}^k \F_i\biggr| = |\A\cap \C| + |\F_k|
\le {|\A|\cdot|\C|\over 2^n} + |\F_k|
\le \biggl(1-{1\over 2^{k-1}}\biggr) |\C| + |\F_k|,$$
where in the last inequality we used the induction hypothesis $|\A| \le 2^n - 2^{n-k+1}$. Since
$|\C| + |\F_k| = 2^n$ and the coefficient of the latter is larger than the coefficient of the former
in the above, the entire expression is largest when $|\F_k| = |\C| = 2^{n-1}$. In this case, we have
$$\biggl|\bigcup_{i=1}^k \F_i\biggr| \le \biggl(1-{1\over 2^{k-1}}\biggr) 2^{n-1} + 2^{n-1} = 2^n-2^{n-k},$$
completing the induction and the proof.\slug

\bye
